# LLM åº”ç”¨çš„æ–­ç‚¹ç»­æ¨ä¸å›æº¯æŠ€æœ¯ï¼šä»åŸç†åˆ°å®è·µ

## ç›®å½•

1. [é—®é¢˜èƒŒæ™¯](#1-é—®é¢˜èƒŒæ™¯)
2. [æ ¸å¿ƒæ¦‚å¿µ](#2-æ ¸å¿ƒæ¦‚å¿µ)
3. [æŠ€æœ¯æ¶æ„](#3-æŠ€æœ¯æ¶æ„)
4. [æ–­ç‚¹ç»­æ¨å®è·µ](#4-æ–­ç‚¹ç»­æ¨å®è·µ)
5. [å›æº¯æœºåˆ¶](#5-å›æº¯æœºåˆ¶)
6. [å¹¶å‘ä¸åˆ†å¸ƒå¼](#6-å¹¶å‘ä¸åˆ†å¸ƒå¼)
7. [LLM åœºæ™¯çš„ç‰¹æ®Šå¤„ç†](#7-llm-åœºæ™¯çš„ç‰¹æ®Šå¤„ç†)
8. [å·¥ç¨‹æœ€ä½³å®è·µ](#8-å·¥ç¨‹æœ€ä½³å®è·µ)
9. [å®æˆ˜æ¡ˆä¾‹](#9-å®æˆ˜æ¡ˆä¾‹)
10. [æ€§èƒ½ä¼˜åŒ–ä¸å¸¸è§é—®é¢˜](#10-æ€§èƒ½ä¼˜åŒ–ä¸å¸¸è§é—®é¢˜)

---

## 1. é—®é¢˜èƒŒæ™¯

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦çŠ¶æ€æŒä¹…åŒ–ï¼Ÿ

åœ¨æ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤æ‚åº”ç”¨æ—¶ï¼Œæˆ‘ä»¬ç»å¸¸é‡åˆ°ä»¥ä¸‹é—®é¢˜ï¼š

**åœºæ™¯ 1ï¼šAPI è°ƒç”¨å¤±è´¥**
```
ç”¨æˆ·æé—® â†’ åˆ†æé—®é¢˜ â†’ æ‰§è¡Œæ­¥éª¤1 â†’ æ‰§è¡Œæ­¥éª¤2 â†’ [ç½‘ç»œè¶…æ—¶] âŒ
éœ€è¦é‡æ–°å¼€å§‹ï¼Œå‰é¢çš„æ­¥éª¤ç™½ç™½æµªè´¹
```

**åœºæ™¯ 2ï¼šé•¿æ—¶é—´è¿è¡Œä»»åŠ¡**
```
å¤šæ­¥æ¨ç†ä»»åŠ¡è¿è¡Œäº† 10 åˆ†é’Ÿï¼Œå®Œæˆäº† 8 ä¸ªæ­¥éª¤
ç”¨æˆ·å…³é—­æµè§ˆå™¨ â†’ æ‰€æœ‰è¿›åº¦ä¸¢å¤± âŒ
```

**åœºæ™¯ 3ï¼šæˆæœ¬æ§åˆ¶**
```
å¤æ‚æ¨ç†ä»»åŠ¡å·²èŠ±è´¹ $2.50
å‘ç°ä¸­é€”æ¨ç†å‡ºé”™ï¼Œéœ€è¦å›é€€é‡æ–°æ‰§è¡Œ
ä½†åˆä¸æƒ³ä¸¢å¼ƒå‰é¢æ­£ç¡®çš„æ­¥éª¤ âŒ
```

**åœºæ™¯ 4ï¼šæ¨ç†é”™è¯¯éœ€è¦å›æº¯**
```
æ­¥éª¤1: åˆ†æé—®é¢˜ âœ“
æ­¥éª¤2: è®¡ç®—ä¸­é—´ç»“æœ âœ“
æ­¥éª¤3: åŸºäºé”™è¯¯å‡è®¾æ¨ç† âœ—
æ­¥éª¤4-6: åŸºäºæ­¥éª¤3çš„é”™è¯¯ç»§ç»­ âœ—

å¸Œæœ›èƒ½å›åˆ°æ­¥éª¤2ï¼Œä¿®æ­£å‡è®¾åé‡æ–°æ‰§è¡Œ
```

è¿™äº›é—®é¢˜çš„æ ¸å¿ƒåœ¨äºï¼š**ç¼ºä¹å¯é çš„çŠ¶æ€ç®¡ç†æœºåˆ¶**ã€‚

### 1.2 è§£å†³æ–¹æ¡ˆæ¦‚è§ˆ

æ–­ç‚¹ç»­æ¨ï¼ˆCheckpointingï¼‰å’Œå›æº¯ï¼ˆRollbackï¼‰æŠ€æœ¯æä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆï¼š

- **æ–­ç‚¹ç»­æ¨**ï¼šåœ¨ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­å®šæœŸä¿å­˜çŠ¶æ€å¿«ç…§ï¼Œå¤±è´¥æ—¶ä»æœ€è¿‘çš„å¿«ç…§æ¢å¤
- **å›æº¯**ï¼šæ”¯æŒå›åˆ°å†å²çŠ¶æ€ç‚¹ï¼Œä¿®æ­£é”™è¯¯åé‡æ–°æ‰§è¡Œ
- **çŠ¶æ€è¿½è¸ª**ï¼šå®Œæ•´è®°å½•æ‰§è¡Œå†å²ï¼Œå®ç°å¯è§‚æµ‹æ€§å’Œå¯å®¡è®¡æ€§

---

## 2. æ ¸å¿ƒæ¦‚å¿µ

### 2.1 Checkpointï¼ˆæ£€æŸ¥ç‚¹ï¼‰

Checkpoint æ˜¯ç³»ç»ŸçŠ¶æ€åœ¨æŸä¸ªæ—¶åˆ»çš„å®Œæ•´å¿«ç…§ã€‚

**ç±»æ¯”**ï¼šå°±åƒæ¸¸æˆçš„å­˜æ¡£ç‚¹ï¼Œè®°å½•äº†å½“å‰æ‰€æœ‰çŠ¶æ€ä¿¡æ¯ã€‚

**åŒ…å«å†…å®¹**ï¼š
```python
{
    "checkpoint_id": "ckpt_abc123",        # å”¯ä¸€æ ‡è¯†
    "thread_id": "conversation_xyz",       # ä¼šè¯/ä»»åŠ¡ ID
    "timestamp": 1704067200,               # ä¿å­˜æ—¶é—´
    "node_name": "execute_reasoning",      # å½“å‰æ‰§è¡ŒèŠ‚ç‚¹
    "state": {                             # å®Œæ•´çŠ¶æ€æ•°æ®
        "question": "åŸå§‹é—®é¢˜",
        "current_step": 3,
        "results": [...]
    },
    "parent_checkpoint_id": "ckpt_abc122", # å‰ä¸€ä¸ªå¿«ç…§
    "metadata": {                          # å…ƒæ•°æ®
        "retry_count": 0,
        "total_cost": 0.05
    }
}
```

### 2.2 Threadï¼ˆçº¿ç¨‹/ä¼šè¯ï¼‰

Thread ä»£è¡¨ä¸€æ¬¡å®Œæ•´çš„ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ï¼ŒåŒ…å«è¯¥ä»»åŠ¡çš„æ‰€æœ‰ Checkpointã€‚

**Thread ä¸ Checkpoint çš„å…³ç³»**ï¼š
```
Thread: conversation_xyz
  â”œâ”€ Checkpoint 1: ä»»åŠ¡å¼€å§‹
  â”œâ”€ Checkpoint 2: å®Œæˆé—®é¢˜åˆ†æ
  â”œâ”€ Checkpoint 3: æ‰§è¡Œæ­¥éª¤1
  â”œâ”€ Checkpoint 4: æ‰§è¡Œæ­¥éª¤2
  â””â”€ Checkpoint 5: ä»»åŠ¡å®Œæˆ
```

### 2.3 Stateï¼ˆçŠ¶æ€ï¼‰

State æ˜¯åº”ç”¨åœ¨æŸä¸ªæ—¶åˆ»çš„æ•°æ®è¡¨ç¤ºï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªç»“æ„åŒ–å¯¹è±¡ã€‚

**ç¤ºä¾‹**ï¼ˆCoT æ¨ç†çŠ¶æ€ï¼‰ï¼š
```python
from typing import TypedDict, List, Dict, Any

class ReasoningState(TypedDict):
    question: str                          # åŸå§‹é—®é¢˜
    reasoning_steps: List[Dict[str, Any]]  # æ¨ç†æ­¥éª¤
    current_step: int                      # å½“å‰æ‰§è¡Œåˆ°ç¬¬å‡ æ­¥
    final_answer: str                      # æœ€ç»ˆç­”æ¡ˆ
    is_complete: bool                      # æ˜¯å¦å®Œæˆ
    metadata: Dict[str, Any]               # å…ƒæ•°æ®
```

### 2.4 Checkpointerï¼ˆæ£€æŸ¥ç‚¹ç®¡ç†å™¨ï¼‰

Checkpointer æ˜¯è´Ÿè´£ä¿å­˜å’ŒåŠ è½½ Checkpoint çš„ç»„ä»¶ã€‚

**æ ¸å¿ƒæ¥å£**ï¼š
```python
class Checkpointer(Protocol):
    def put(self, checkpoint: Checkpoint) -> None:
        """ä¿å­˜ checkpoint"""
        pass

    def get(self, checkpoint_id: str) -> Checkpoint:
        """åŠ è½½æŒ‡å®š checkpoint"""
        pass

    def list(self, thread_id: str) -> List[Checkpoint]:
        """è·å–æŸä¸ª thread çš„æ‰€æœ‰ checkpoint"""
        pass
```

---

## 3. æŠ€æœ¯æ¶æ„

### 3.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 åº”ç”¨å±‚ï¼ˆApplicationï¼‰                 â”‚
â”‚          LLM å·¥ä½œæµã€æ¨ç†å¼•æ“ã€ä¸šåŠ¡é€»è¾‘               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ invoke() / stream()
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangGraph ç¼–æ’å±‚ï¼ˆOrchestrationï¼‰        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Node A  â”‚â”€â”€â–¶â”‚  Node B  â”‚â”€â”€â–¶â”‚  Node C  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚              â”‚              â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                        â”‚                             â”‚
â”‚                        â–¼                             â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â”‚ Checkpoint Hook  â”‚ (åœ¨æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œå‰å) â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ put() / get()
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Checkpointer å±‚ï¼ˆState Managementï¼‰         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  åºåˆ—åŒ–/ååºåˆ—åŒ– (JSON/Pickle/Protobuf)     â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚  ç‰ˆæœ¬ç®¡ç†ã€å‹ç¼©ã€åŠ å¯†                       â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚  å¹¶å‘æ§åˆ¶ï¼ˆä¹è§‚é”/æ‚²è§‚é”ï¼‰                  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ SQL/NoSQL API
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å­˜å‚¨å±‚ï¼ˆPersistenceï¼‰                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Memory  â”‚  â”‚  SQLite    â”‚  â”‚PostgreSQLâ”‚        â”‚
â”‚  â”‚  (å¼€å‘)  â”‚  â”‚  (å•æœº)    â”‚  â”‚ (ç”Ÿäº§)   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚  Redis   â”‚  â”‚    S3      â”‚                      â”‚
â”‚  â”‚ (åˆ†å¸ƒå¼) â”‚  â”‚  (å½’æ¡£)    â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 ä¿å­˜æ—¶æœº

Checkpoint é€šå¸¸åœ¨ä»¥ä¸‹æ—¶æœºä¿å­˜ï¼š

1. **èŠ‚ç‚¹æ‰§è¡Œå‰**ï¼ˆBefore Hookï¼‰
   - ä¿å­˜è¿›å…¥èŠ‚ç‚¹æ—¶çš„çŠ¶æ€
   - ç”¨äºé‡è¯•æ—¶è·³è¿‡å·²å®ŒæˆèŠ‚ç‚¹

2. **èŠ‚ç‚¹æ‰§è¡Œå**ï¼ˆAfter Hookï¼‰
   - ä¿å­˜èŠ‚ç‚¹è¾“å‡ºåçš„æ–°çŠ¶æ€
   - è®°å½•èŠ‚ç‚¹æ‰§è¡Œç»“æœ

3. **æ¡ä»¶è¾¹è¯„ä¼°æ—¶**ï¼ˆConditional Edgeï¼‰
   - ä¿å­˜è·¯ç”±å†³ç­–ç‚¹çš„çŠ¶æ€
   - æ”¯æŒå›æº¯åˆ°åˆ†æ”¯ç‚¹

4. **æ‰‹åŠ¨è§¦å‘**ï¼ˆManualï¼‰
   - ç”¨æˆ·ä¸»åŠ¨ä¿å­˜
   - å…³é”®ä¸šåŠ¡èŠ‚ç‚¹

**å¯é…ç½®ç­–ç•¥**ï¼š
```python
# ä»…åœ¨å…³é”®èŠ‚ç‚¹ä¿å­˜
checkpoint_config = {
    "save_on": ["analyze", "validate"],  # æŒ‡å®šèŠ‚ç‚¹
    "save_interval": 300,                # æ¯ 5 åˆ†é’Ÿ
    "max_checkpoints": 10                # æœ€å¤šä¿ç•™ 10 ä¸ª
}
```

### 3.3 å­˜å‚¨åç«¯é€‰æ‹©

| å­˜å‚¨ç±»å‹ | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|---------|---------|------|------|
| **MemorySaver** | å¼€å‘/æµ‹è¯• | é›¶é…ç½®ã€å¿«é€Ÿ | è¿›ç¨‹é€€å‡ºä¸¢å¤± |
| **SQLite** | å•æœºåº”ç”¨ | æ–‡ä»¶æŒä¹…åŒ–ã€è½»é‡ | å¹¶å‘å†™å—é™ |
| **PostgreSQL** | ç”Ÿäº§ç¯å¢ƒ | é«˜å¯ç”¨ã€ACID | éœ€è¦é¢å¤–åŸºç¡€è®¾æ–½ |
| **Redis** | åˆ†å¸ƒå¼ç³»ç»Ÿ | é«˜æ€§èƒ½ã€æ”¯æŒ TTL | å†…å­˜æˆæœ¬é«˜ |
| **S3/OSS** | å†·æ•°æ®å½’æ¡£ | ä½æˆæœ¬ã€æ— é™å®¹é‡ | è¯»å†™å»¶è¿Ÿé«˜ |

---

## 4. æ–­ç‚¹ç»­æ¨å®è·µ

### 4.1 åŸºç¡€å®ç°ï¼šSQLite Checkpointer

**å®Œæ•´ä»£ç ç¤ºä¾‹**ï¼š

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
from typing import TypedDict, List
import sqlite3

# 1. å®šä¹‰çŠ¶æ€
class MyState(TypedDict):
    messages: List[str]
    current_step: int
    result: str

# 2. åˆ›å»º SQLite checkpointer
conn = sqlite3.connect("checkpoints.db", check_same_thread=False)
checkpointer = SqliteSaver(conn)

# 3. å®šä¹‰å·¥ä½œæµ
def step1(state: MyState) -> MyState:
    print(f"æ‰§è¡Œæ­¥éª¤ 1ï¼Œå½“å‰æ­¥éª¤: {state['current_step']}")
    return {
        **state,
        "messages": state["messages"] + ["æ­¥éª¤1å®Œæˆ"],
        "current_step": 1
    }

def step2(state: MyState) -> MyState:
    print(f"æ‰§è¡Œæ­¥éª¤ 2ï¼Œå½“å‰æ­¥éª¤: {state['current_step']}")
    # æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„æ“ä½œ
    import random
    if random.random() < 0.3:  # 30% æ¦‚ç‡å¤±è´¥
        raise Exception("æ­¥éª¤2æ‰§è¡Œå¤±è´¥ï¼")

    return {
        **state,
        "messages": state["messages"] + ["æ­¥éª¤2å®Œæˆ"],
        "current_step": 2
    }

def step3(state: MyState) -> MyState:
    print(f"æ‰§è¡Œæ­¥éª¤ 3ï¼Œå½“å‰æ­¥éª¤: {state['current_step']}")
    return {
        **state,
        "messages": state["messages"] + ["æ­¥éª¤3å®Œæˆ"],
        "current_step": 3,
        "result": "ä»»åŠ¡å®Œæˆï¼"
    }

# 4. æ„å»ºå›¾
workflow = StateGraph(MyState)
workflow.add_node("step1", step1)
workflow.add_node("step2", step2)
workflow.add_node("step3", step3)

workflow.set_entry_point("step1")
workflow.add_edge("step1", "step2")
workflow.add_edge("step2", "step3")
workflow.add_edge("step3", END)

# 5. ç¼–è¯‘æ—¶ä¼ å…¥ checkpointer
graph = workflow.compile(checkpointer=checkpointer)

# 6. æ‰§è¡Œä»»åŠ¡
initial_state = {
    "messages": [],
    "current_step": 0,
    "result": ""
}

config = {
    "configurable": {
        "thread_id": "task_001"  # å…³é”®ï¼šæŒ‡å®š thread_id
    }
}

try:
    result = graph.invoke(initial_state, config=config)
    print("ä»»åŠ¡æˆåŠŸå®Œæˆ:", result)
except Exception as e:
    print(f"ä»»åŠ¡å¤±è´¥: {e}")
    print("å¯ä»¥ç¨åä½¿ç”¨ç›¸åŒ thread_id æ¢å¤æ‰§è¡Œ")

# 7. æ¢å¤æ‰§è¡Œï¼ˆè‡ªåŠ¨ä»æœ€æ–° checkpoint ç»§ç»­ï¼‰
print("\n--- æ¢å¤æ‰§è¡Œ ---")
result = graph.invoke(None, config=config)  # state=None è‡ªåŠ¨åŠ è½½
print("æ¢å¤åç»“æœ:", result)
```

**è¿è¡Œæµç¨‹è§£æ**ï¼š

```
é¦–æ¬¡æ‰§è¡Œ:
  step1 âœ“ â†’ checkpoint ä¿å­˜
  step2 âœ“ â†’ checkpoint ä¿å­˜
  step3 âœ— â†’ å¤±è´¥

æ¢å¤æ‰§è¡Œ:
  åŠ è½½æœ€æ–° checkpoint (step2 å®Œæˆåçš„çŠ¶æ€)
  è·³è¿‡ step1, step2
  ç›´æ¥ä» step3 å¼€å§‹
  step3 âœ“ â†’ å®Œæˆ
```

### 4.2 PostgreSQL ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
from langgraph.checkpoint.postgres import PostgresSaver
import psycopg2

# 1. åˆ›å»ºæ•°æ®åº“è¿æ¥
conn_string = "postgresql://user:password@localhost:5432/llm_app"
conn = psycopg2.connect(conn_string)

# 2. åˆå§‹åŒ– checkpointerï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºè¡¨ï¼‰
checkpointer = PostgresSaver(conn)
checkpointer.setup()  # åˆ›å»ºå¿…è¦çš„æ•°æ®åº“è¡¨

# 3. ç¼–è¯‘å›¾
graph = workflow.compile(checkpointer=checkpointer)

# 4. ä½¿ç”¨æ–¹å¼ä¸ SQLite å®Œå…¨ç›¸åŒ
config = {"configurable": {"thread_id": "prod_task_123"}}
result = graph.invoke(initial_state, config=config)
```

**æ•°æ®åº“è¡¨ç»“æ„**ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰ï¼š

```sql
CREATE TABLE checkpoints (
    thread_id VARCHAR(255) NOT NULL,
    checkpoint_id VARCHAR(255) NOT NULL PRIMARY KEY,
    parent_checkpoint_id VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    checkpoint_data JSONB NOT NULL,
    metadata JSONB,
    INDEX idx_thread_id (thread_id),
    INDEX idx_created_at (created_at)
);
```

### 4.3 é”™è¯¯æ¢å¤æµç¨‹

**å®Œæ•´é”™è¯¯å¤„ç†ç­–ç•¥**ï¼š

```python
def execute_with_retry(graph, initial_state, thread_id, max_retries=3):
    """
    å¸¦è‡ªåŠ¨é‡è¯•çš„æ‰§è¡Œ
    """
    config = {"configurable": {"thread_id": thread_id}}

    for attempt in range(max_retries):
        try:
            # ç¬¬ä¸€æ¬¡æ‰§è¡Œä¼ å…¥ initial_stateï¼Œåç»­ä¼ å…¥ None è‡ªåŠ¨æ¢å¤
            state_input = initial_state if attempt == 0 else None
            result = graph.invoke(state_input, config=config)

            print(f"æ‰§è¡ŒæˆåŠŸ (å°è¯• {attempt + 1}/{max_retries})")
            return result

        except Exception as e:
            print(f"æ‰§è¡Œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")

            if attempt < max_retries - 1:
                print("ç­‰å¾… 5 ç§’åé‡è¯•...")
                time.sleep(5)
            else:
                print("è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒæ‰§è¡Œ")
                raise

# ä½¿ç”¨ç¤ºä¾‹
result = execute_with_retry(
    graph=graph,
    initial_state={"messages": [], "current_step": 0},
    thread_id="resilient_task_001",
    max_retries=3
)
```

### 4.4 æŸ¥çœ‹å’Œç®¡ç† Checkpoints

```python
def inspect_checkpoints(graph, thread_id):
    """
    æ£€æŸ¥æŸä¸ª thread çš„æ‰€æœ‰ checkpoint
    """
    config = {"configurable": {"thread_id": thread_id}}

    # è·å–æ‰€æœ‰å†å²çŠ¶æ€
    history = graph.get_state_history(config)

    print(f"\n=== Thread: {thread_id} ===")
    for i, checkpoint in enumerate(history):
        print(f"\nCheckpoint {i + 1}:")
        print(f"  ID: {checkpoint.config['configurable']['checkpoint_id'][:16]}...")
        print(f"  å½“å‰æ­¥éª¤: {checkpoint.values.get('current_step', 'N/A')}")
        print(f"  æ¶ˆæ¯æ•°: {len(checkpoint.values.get('messages', []))}")

        # æŸ¥çœ‹å…ƒæ•°æ®
        if hasattr(checkpoint, 'metadata'):
            print(f"  å…ƒæ•°æ®: {checkpoint.metadata}")

    return list(history)

# ä½¿ç”¨ç¤ºä¾‹
checkpoints = inspect_checkpoints(graph, "task_001")
```

---

## 5. å›æº¯æœºåˆ¶

### 5.1 æ—¶é—´æ—…è¡Œï¼ˆTime Travelï¼‰

å›æº¯åˆ°æŒ‡å®šçš„å†å²çŠ¶æ€ç‚¹ï¼Œä»è¯¥ç‚¹é‡æ–°æ‰§è¡Œã€‚

**å®Œæ•´ç¤ºä¾‹**ï¼š

```python
def time_travel_demo():
    """
    æ¼”ç¤ºæ—¶é—´æ—…è¡ŒåŠŸèƒ½
    """
    # 1. æ­£å¸¸æ‰§è¡Œä»»åŠ¡
    config = {"configurable": {"thread_id": "time_travel_demo"}}
    initial_state = {"messages": [], "current_step": 0, "result": ""}

    try:
        graph.invoke(initial_state, config=config)
    except:
        pass  # å¿½ç•¥å¯èƒ½çš„é”™è¯¯

    # 2. æŸ¥çœ‹æ‰€æœ‰ checkpoint
    history = list(graph.get_state_history(config))
    print(f"\næ‰¾åˆ° {len(history)} ä¸ªå†å²çŠ¶æ€ç‚¹")

    for i, checkpoint in enumerate(history):
        step = checkpoint.values.get('current_step', 0)
        print(f"  [{i}] æ­¥éª¤ {step}: {checkpoint.values.get('messages', [])}")

    # 3. é€‰æ‹©å›æº¯ç‚¹ï¼ˆå›åˆ°æ­¥éª¤ 1 å®Œæˆåï¼‰
    target_checkpoint = None
    for checkpoint in history:
        if checkpoint.values.get('current_step') == 1:
            target_checkpoint = checkpoint
            break

    if not target_checkpoint:
        print("æœªæ‰¾åˆ°ç›®æ ‡ checkpoint")
        return

    # 4. ä»è¯¥ checkpoint æ¢å¤
    rollback_config = {
        "configurable": {
            "thread_id": "time_travel_demo",
            "checkpoint_id": target_checkpoint.config['configurable']['checkpoint_id']
        }
    }

    print(f"\nå›æº¯åˆ°æ­¥éª¤ 1ï¼Œä»æ­¥éª¤ 2 é‡æ–°æ‰§è¡Œ...")
    result = graph.invoke(None, config=rollback_config)

    print(f"é‡æ–°æ‰§è¡Œå®Œæˆ: {result}")

time_travel_demo()
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
æ‰¾åˆ° 4 ä¸ªå†å²çŠ¶æ€ç‚¹
  [0] æ­¥éª¤ 3: ['æ­¥éª¤1å®Œæˆ', 'æ­¥éª¤2å®Œæˆ', 'æ­¥éª¤3å®Œæˆ']
  [1] æ­¥éª¤ 2: ['æ­¥éª¤1å®Œæˆ', 'æ­¥éª¤2å®Œæˆ']
  [2] æ­¥éª¤ 1: ['æ­¥éª¤1å®Œæˆ']
  [3] æ­¥éª¤ 0: []

å›æº¯åˆ°æ­¥éª¤ 1ï¼Œä»æ­¥éª¤ 2 é‡æ–°æ‰§è¡Œ...
æ‰§è¡Œæ­¥éª¤ 2ï¼Œå½“å‰æ­¥éª¤: 1
æ‰§è¡Œæ­¥éª¤ 3ï¼Œå½“å‰æ­¥éª¤: 2
é‡æ–°æ‰§è¡Œå®Œæˆ: {...}
```

### 5.2 é€‰æ‹©æ€§é‡æ”¾

åªé‡æ–°æ‰§è¡Œå—å½±å“çš„èŠ‚ç‚¹ï¼Œè€Œä¸æ˜¯ä»å¤´å¼€å§‹ã€‚

**ä¾èµ–è¿½è¸ªç¤ºä¾‹**ï¼š

```python
class DependencyTracker:
    """
    è·Ÿè¸ªèŠ‚ç‚¹ä¾èµ–å…³ç³»
    """
    def __init__(self):
        self.dependencies = {}

    def add_dependency(self, node: str, depends_on: List[str]):
        """è®°å½•èŠ‚ç‚¹ä¾èµ–"""
        self.dependencies[node] = depends_on

    def get_affected_nodes(self, changed_node: str, all_nodes: List[str]) -> List[str]:
        """
        è·å–å—å½±å“çš„èŠ‚ç‚¹
        """
        affected = set([changed_node])

        # é€’å½’æŸ¥æ‰¾ä¾èµ–è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰èŠ‚ç‚¹
        changed = True
        while changed:
            changed = False
            for node, deps in self.dependencies.items():
                if node not in affected and any(d in affected for d in deps):
                    affected.add(node)
                    changed = True

        # æŒ‰æ‰§è¡Œé¡ºåºæ’åº
        return [n for n in all_nodes if n in affected]

# ä½¿ç”¨ç¤ºä¾‹
tracker = DependencyTracker()
tracker.add_dependency("analyze", [])
tracker.add_dependency("calculate_base", ["analyze"])
tracker.add_dependency("calculate_derived", ["calculate_base"])
tracker.add_dependency("validate", ["calculate_derived"])
tracker.add_dependency("format_output", ["validate"])

# å‡è®¾ calculate_base èŠ‚ç‚¹å‡ºé”™éœ€è¦é‡æ–°æ‰§è¡Œ
all_nodes = ["analyze", "calculate_base", "calculate_derived", "validate", "format_output"]
affected = tracker.get_affected_nodes("calculate_base", all_nodes)

print(f"éœ€è¦é‡æ–°æ‰§è¡Œçš„èŠ‚ç‚¹: {affected}")
# è¾“å‡º: ['calculate_base', 'calculate_derived', 'validate', 'format_output']
```

### 5.3 åˆ†æ”¯ç®¡ç†

å›æº¯åäº§ç”Ÿæ–°çš„æ‰§è¡Œåˆ†æ”¯ã€‚

**åˆ†æ”¯å¯è§†åŒ–**ï¼š
```
åˆå§‹æ‰§è¡Œ:
  step1 â†’ step2(v1) â†’ step3(v1) â†’ å®Œæˆ

å›æº¯åˆ° step1 åé‡æ–°æ‰§è¡Œ:
  step1 â”¬â†’ step2(v1) â†’ step3(v1) â†’ å®Œæˆ
        â””â†’ step2(v2) â†’ step3(v2) â†’ å®Œæˆï¼ˆæ–°åˆ†æ”¯ï¼‰
```

**å®ç°åˆ†æ”¯ç®¡ç†**ï¼š

```python
def create_branch(graph, base_thread_id, branch_name):
    """
    ä»ç°æœ‰ thread åˆ›å»ºåˆ†æ”¯
    """
    # 1. è·å–åŸºç¡€ thread çš„æœ€æ–°çŠ¶æ€
    base_config = {"configurable": {"thread_id": base_thread_id}}
    base_state = graph.get_state(base_config)

    # 2. åˆ›å»ºæ–° thread
    branch_thread_id = f"{base_thread_id}_branch_{branch_name}"
    branch_config = {"configurable": {"thread_id": branch_thread_id}}

    # 3. ä»åŸºç¡€çŠ¶æ€ç»§ç»­æ‰§è¡Œ
    result = graph.invoke(base_state.values, config=branch_config)

    print(f"åˆ›å»ºåˆ†æ”¯: {base_thread_id} â†’ {branch_thread_id}")
    return branch_thread_id, result

# ä½¿ç”¨ç¤ºä¾‹
base_result = graph.invoke(initial_state, config={"configurable": {"thread_id": "main"}})

# åˆ›å»ºä¸¤ä¸ªä¸åŒçš„åˆ†æ”¯
branch1_id, branch1_result = create_branch(graph, "main", "experiment_a")
branch2_id, branch2_result = create_branch(graph, "main", "experiment_b")
```

---

## 6. å¹¶å‘ä¸åˆ†å¸ƒå¼

### 6.1 ä¹è§‚é”æœºåˆ¶

åœ¨å¤šè¿›ç¨‹/å¤šçº¿ç¨‹ç¯å¢ƒä¸‹ï¼Œé¿å…å¹¶å‘ä¿®æ”¹å†²çªã€‚

**åŸç†**ï¼š
```python
class OptimisticLockCheckpointer:
    """
    å¸¦ä¹è§‚é”çš„ Checkpointer
    """
    def put(self, checkpoint_data, expected_version):
        """
        ä¿å­˜ checkpointï¼Œå¦‚æœç‰ˆæœ¬ä¸åŒ¹é…åˆ™å¤±è´¥
        """
        current_version = self._get_current_version(checkpoint_data['thread_id'])

        if current_version != expected_version:
            raise ConcurrentModificationError(
                f"ç‰ˆæœ¬å†²çª: æœŸæœ› {expected_version}, å®é™… {current_version}"
            )

        # å†™å…¥æ–°ç‰ˆæœ¬
        checkpoint_data['version'] = current_version + 1
        self._write_to_storage(checkpoint_data)

    def get(self, thread_id):
        """
        è·å– checkpoint åŠå…¶ç‰ˆæœ¬å·
        """
        checkpoint = self._read_from_storage(thread_id)
        return checkpoint, checkpoint.get('version', 0)

# ä½¿ç”¨ç¤ºä¾‹
checkpoint, version = checkpointer.get("thread_001")

# ä¿®æ”¹çŠ¶æ€
checkpoint['state']['current_step'] += 1

# å°è¯•ä¿å­˜ï¼ˆå¦‚æœç‰ˆæœ¬å·²å˜ï¼Œä¼šæŠ›å‡ºå¼‚å¸¸ï¼‰
try:
    checkpointer.put(checkpoint, expected_version=version)
except ConcurrentModificationError:
    print("æ£€æµ‹åˆ°å¹¶å‘ä¿®æ”¹ï¼Œéœ€è¦é‡æ–°åŠ è½½çŠ¶æ€")
```

### 6.2 åˆ†å¸ƒå¼ Checkpoint

ä½¿ç”¨ Redis å®ç°è·¨æœºå™¨çš„çŠ¶æ€å…±äº«ã€‚

**Redis Checkpointer å®ç°**ï¼š

```python
import redis
import json
import pickle
from typing import Optional

class RedisCheckpointer:
    """
    åŸºäº Redis çš„åˆ†å¸ƒå¼ Checkpointer
    """
    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis = redis.from_url(redis_url)
        self.ttl = 86400  # 24 å°æ—¶è¿‡æœŸ

    def put(self, thread_id: str, checkpoint_data: dict) -> None:
        """
        ä¿å­˜ checkpoint
        """
        key = f"checkpoint:{thread_id}"

        # åºåˆ—åŒ–æ•°æ®
        serialized = pickle.dumps(checkpoint_data)

        # ä½¿ç”¨ ZADD ä¿å­˜åˆ°æœ‰åºé›†åˆï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼‰
        score = checkpoint_data['timestamp']
        checkpoint_id = checkpoint_data['checkpoint_id']

        self.redis.zadd(key, {serialized: score})

        # è®¾ç½®è¿‡æœŸæ—¶é—´
        self.redis.expire(key, self.ttl)

        # é™åˆ¶ä¿ç•™çš„ checkpoint æ•°é‡ï¼ˆåªä¿ç•™æœ€æ–° 10 ä¸ªï¼‰
        self.redis.zremrangebyrank(key, 0, -11)

    def get_latest(self, thread_id: str) -> Optional[dict]:
        """
        è·å–æœ€æ–°çš„ checkpoint
        """
        key = f"checkpoint:{thread_id}"

        # è·å–æœ€æ–°çš„ checkpointï¼ˆåˆ†æ•°æœ€é«˜ï¼‰
        results = self.redis.zrange(key, -1, -1)

        if not results:
            return None

        return pickle.loads(results[0])

    def get_history(self, thread_id: str, limit: int = 10) -> list:
        """
        è·å–å†å² checkpoint
        """
        key = f"checkpoint:{thread_id}"

        # è·å–æœ€è¿‘çš„ N ä¸ª checkpoint
        results = self.redis.zrange(key, -limit, -1)

        return [pickle.loads(r) for r in results]

# ä½¿ç”¨ç¤ºä¾‹
checkpointer = RedisCheckpointer("redis://localhost:6379")

# ä¿å­˜ checkpoint
checkpointer.put("distributed_task_001", {
    "thread_id": "distributed_task_001",
    "checkpoint_id": "ckpt_123",
    "timestamp": 1704067200,
    "state": {"current_step": 2}
})

# åœ¨å¦ä¸€å°æœºå™¨ä¸Šæ¢å¤
latest = checkpointer.get_latest("distributed_task_001")
print(f"æ¢å¤çŠ¶æ€: {latest}")
```

### 6.3 æ•…éšœè½¬ç§»ï¼ˆFailoverï¼‰

å½“æ‰§è¡ŒèŠ‚ç‚¹å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨å°†ä»»åŠ¡è½¬ç§»åˆ°å¥åº·èŠ‚ç‚¹ã€‚

**å¥åº·æ£€æŸ¥ä¸æ¢å¤**ï¼š

```python
import time
from threading import Thread

class FailoverManager:
    """
    æ•…éšœè½¬ç§»ç®¡ç†å™¨
    """
    def __init__(self, checkpointer, heartbeat_interval=10):
        self.checkpointer = checkpointer
        self.heartbeat_interval = heartbeat_interval
        self.active_tasks = {}  # {thread_id: last_heartbeat}

    def register_task(self, thread_id: str):
        """æ³¨å†Œæ´»è·ƒä»»åŠ¡"""
        self.active_tasks[thread_id] = time.time()

    def heartbeat(self, thread_id: str):
        """æ›´æ–°å¿ƒè·³"""
        self.active_tasks[thread_id] = time.time()

    def check_health(self):
        """
        æ£€æŸ¥ä»»åŠ¡å¥åº·çŠ¶æ€
        """
        now = time.time()
        timeout = self.heartbeat_interval * 3  # 3 å€å¿ƒè·³é—´éš”

        failed_tasks = []
        for thread_id, last_beat in self.active_tasks.items():
            if now - last_beat > timeout:
                failed_tasks.append(thread_id)

        return failed_tasks

    def recover_task(self, thread_id: str, graph):
        """
        æ¢å¤å¤±è´¥çš„ä»»åŠ¡
        """
        print(f"æ£€æµ‹åˆ°ä»»åŠ¡ {thread_id} å¤±è´¥ï¼Œå¼€å§‹æ¢å¤...")

        # ä» checkpoint æ¢å¤
        config = {"configurable": {"thread_id": thread_id}}

        try:
            result = graph.invoke(None, config=config)
            print(f"ä»»åŠ¡ {thread_id} æ¢å¤æˆåŠŸ")
            return result
        except Exception as e:
            print(f"ä»»åŠ¡ {thread_id} æ¢å¤å¤±è´¥: {e}")
            raise

    def start_monitoring(self, graph):
        """
        å¯åŠ¨åå°ç›‘æ§çº¿ç¨‹
        """
        def monitor():
            while True:
                failed_tasks = self.check_health()
                for thread_id in failed_tasks:
                    try:
                        self.recover_task(thread_id, graph)
                    except Exception as e:
                        print(f"æ— æ³•æ¢å¤ä»»åŠ¡ {thread_id}: {e}")

                time.sleep(self.heartbeat_interval)

        thread = Thread(target=monitor, daemon=True)
        thread.start()

# ä½¿ç”¨ç¤ºä¾‹
failover_manager = FailoverManager(checkpointer)

def execute_with_failover(graph, state, thread_id):
    """
    å¸¦æ•…éšœè½¬ç§»çš„æ‰§è¡Œ
    """
    failover_manager.register_task(thread_id)

    config = {"configurable": {"thread_id": thread_id}}

    # æ‰§è¡Œè¿‡ç¨‹ä¸­å®šæœŸå‘é€å¿ƒè·³
    # ï¼ˆå®é™…åº”è¯¥åœ¨èŠ‚ç‚¹æ‰§è¡Œä¸­æ’å…¥å¿ƒè·³é€»è¾‘ï¼‰
    failover_manager.heartbeat(thread_id)

    result = graph.invoke(state, config=config)

    # ä»»åŠ¡å®Œæˆï¼Œç§»é™¤ç›‘æ§
    del failover_manager.active_tasks[thread_id]

    return result
```

---

## 7. LLM åœºæ™¯çš„ç‰¹æ®Šå¤„ç†

### 7.1 åº”å¯¹ LLM çš„éç¡®å®šæ€§

å³ä½¿ä½¿ç”¨ç›¸åŒçš„è¾“å…¥ï¼ŒLLM ä¹Ÿå¯èƒ½è¿”å›ä¸åŒç»“æœï¼ˆå°¤å…¶æ˜¯ temperature > 0 æ—¶ï¼‰ã€‚

**ç­–ç•¥ 1ï¼šç¼“å­˜ LLM å“åº”**

```python
class LLMCachedCheckpointer:
    """
    ç¼“å­˜ LLM è°ƒç”¨ç»“æœçš„ Checkpointer
    """
    def __init__(self, base_checkpointer):
        self.base = base_checkpointer

    def save_with_llm_cache(self, thread_id, state, llm_call_log):
        """
        ä¿å­˜çŠ¶æ€å’Œ LLM è°ƒç”¨å†å²
        """
        checkpoint_data = {
            "thread_id": thread_id,
            "checkpoint_id": f"ckpt_{int(time.time() * 1000)}",
            "timestamp": time.time(),
            "state": state,
            "llm_cache": llm_call_log  # å…³é”®ï¼šç¼“å­˜ LLM è°ƒç”¨
        }

        self.base.put(thread_id, checkpoint_data)

    def restore_with_cache(self, thread_id):
        """
        æ¢å¤çŠ¶æ€å’Œ LLM ç¼“å­˜
        """
        checkpoint = self.base.get_latest(thread_id)

        if not checkpoint:
            return None, {}

        return checkpoint['state'], checkpoint.get('llm_cache', {})

# ä½¿ç”¨ç¤ºä¾‹
class CachedLLMWrapper:
    """
    å¸¦ç¼“å­˜çš„ LLM åŒ…è£…å™¨
    """
    def __init__(self, llm, cache=None):
        self.llm = llm
        self.cache = cache or {}

    def invoke(self, prompt):
        """
        è°ƒç”¨ LLMï¼Œä¼˜å…ˆä½¿ç”¨ç¼“å­˜
        """
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = hash(prompt)

        if cache_key in self.cache:
            print(f"ä½¿ç”¨ç¼“å­˜ç»“æœ: {prompt[:50]}...")
            return self.cache[cache_key]

        # è°ƒç”¨çœŸå® LLM
        response = self.llm.invoke(prompt)

        # å­˜å…¥ç¼“å­˜
        self.cache[cache_key] = response

        return response

    def get_cache_log(self):
        """è·å–ç¼“å­˜æ—¥å¿—"""
        return self.cache

# é›†æˆåˆ°å·¥ä½œæµ
state, llm_cache = checkpointer.restore_with_cache("thread_001")
cached_llm = CachedLLMWrapper(llm, cache=llm_cache)

# æ‰§è¡Œæ—¶ä½¿ç”¨ç¼“å­˜çš„ LLM
# ... èŠ‚ç‚¹æ‰§è¡Œ ...

# ä¿å­˜æ—¶è®°å½•ç¼“å­˜
checkpointer.save_with_llm_cache(
    "thread_001",
    final_state,
    cached_llm.get_cache_log()
)
```

**ç­–ç•¥ 2ï¼šå›ºå®šéšæœºç§å­**

```python
from langchain_openai import ChatOpenAI

# temperature=0 æé«˜ç¡®å®šæ€§
llm = ChatOpenAI(
    model="gpt-4",
    temperature=0,  # å…³é”®ï¼šç¡®å®šæ€§è¾“å‡º
    model_kwargs={"seed": 42}  # å›ºå®šç§å­ï¼ˆéƒ¨åˆ†æ¨¡å‹æ”¯æŒï¼‰
)
```

### 7.2 æ¨ç†æ­¥éª¤çš„åŸå­æ€§

å•ä¸ªæ¨ç†æ­¥éª¤å¯èƒ½å¾ˆé•¿ï¼Œéœ€è¦æ”¯æŒæ›´ç»†ç²’åº¦çš„ checkpointã€‚

**å­æ­¥éª¤åˆ†è§£**ï¼š

```python
def execute_complex_reasoning(state: MyState) -> MyState:
    """
    å¤æ‚æ¨ç†æ­¥éª¤ï¼Œåˆ†è§£ä¸ºå¤šä¸ªå­æ­¥éª¤
    """
    # å­æ­¥éª¤ 1
    intermediate_result_1 = sub_step_1(state)
    save_checkpoint(state, "reasoning_substep_1")

    # å­æ­¥éª¤ 2
    intermediate_result_2 = sub_step_2(intermediate_result_1)
    save_checkpoint(state, "reasoning_substep_2")

    # å­æ­¥éª¤ 3
    final_result = sub_step_3(intermediate_result_2)
    save_checkpoint(state, "reasoning_complete")

    return final_result
```

**æµå¼ Checkpoint**ï¼š

```python
def streaming_checkpoint_wrapper(node_func, checkpointer, thread_id):
    """
    ä¸ºèŠ‚ç‚¹æ·»åŠ æµå¼ checkpoint èƒ½åŠ›
    """
    def wrapped(state):
        # å¼€å§‹æ‰§è¡Œ
        checkpointer.save(thread_id, state, status="in_progress")

        # æ‰§è¡ŒèŠ‚ç‚¹
        result = node_func(state)

        # å®Œæˆæ‰§è¡Œ
        checkpointer.save(thread_id, result, status="completed")

        return result

    return wrapped
```

### 7.3 æˆæœ¬è¿½è¸ª

åœ¨ checkpoint ä¸­è®°å½• token ä½¿ç”¨å’Œæˆæœ¬ã€‚

**æˆæœ¬è®¡ç®—å™¨**ï¼š

```python
class CostTracker:
    """
    æˆæœ¬è¿½è¸ªå™¨
    """
    PRICING = {
        "gpt-4": {"input": 0.03 / 1000, "output": 0.06 / 1000},
        "gpt-3.5-turbo": {"input": 0.001 / 1000, "output": 0.002 / 1000}
    }

    def __init__(self):
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.model_name = "gpt-4"

    def record_usage(self, input_tokens: int, output_tokens: int):
        """è®°å½• token ä½¿ç”¨"""
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens

    def get_cost(self) -> float:
        """è®¡ç®—æ€»æˆæœ¬"""
        pricing = self.PRICING.get(self.model_name, self.PRICING["gpt-4"])

        input_cost = self.total_input_tokens * pricing["input"]
        output_cost = self.total_output_tokens * pricing["output"]

        return input_cost + output_cost

    def to_dict(self):
        """åºåˆ—åŒ–"""
        return {
            "input_tokens": self.total_input_tokens,
            "output_tokens": self.total_output_tokens,
            "total_cost": self.get_cost(),
            "model": self.model_name
        }

# é›†æˆåˆ° checkpoint
class CostAwareCheckpointer:
    """
    å¸¦æˆæœ¬è¿½è¸ªçš„ Checkpointer
    """
    def save(self, thread_id, state, cost_tracker: CostTracker):
        checkpoint_data = {
            "thread_id": thread_id,
            "state": state,
            "cost_info": cost_tracker.to_dict()
        }
        self._write(checkpoint_data)

# ä½¿ç”¨ç¤ºä¾‹
cost_tracker = CostTracker()

# åœ¨æ¯æ¬¡ LLM è°ƒç”¨åè®°å½•
response = llm.invoke(prompt)
cost_tracker.record_usage(
    input_tokens=response.usage.prompt_tokens,
    output_tokens=response.usage.completion_tokens
)

# ä¿å­˜ checkpoint æ—¶è®°å½•æˆæœ¬
checkpointer.save("thread_001", state, cost_tracker)

# æ¢å¤æ—¶æ£€æŸ¥æˆæœ¬
checkpoint = checkpointer.get("thread_001")
if checkpoint['cost_info']['total_cost'] > budget:
    raise BudgetExceededError("è¶…å‡ºæˆæœ¬é¢„ç®—")
```

---

## 8. å·¥ç¨‹æœ€ä½³å®è·µ

### 8.1 Checkpoint ç²’åº¦é€‰æ‹©

**æƒè¡¡å› ç´ **ï¼š

| ç²’åº¦ | å­˜å‚¨å¼€é”€ | æ¢å¤ç²¾åº¦ | I/O é¢‘ç‡ | é€‚ç”¨åœºæ™¯ |
|------|---------|---------|---------|---------|
| **ç²—ç²’åº¦**ï¼ˆæ¯ä¸ªé˜¶æ®µï¼‰ | ä½ | ä½ | ä½ | çŸ­ä»»åŠ¡ã€å»‰ä»·æ“ä½œ |
| **ä¸­ç²’åº¦**ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ï¼‰ | ä¸­ | ä¸­ | ä¸­ | æ¨èç”¨äºå¤§å¤šæ•°åœºæ™¯ |
| **ç»†ç²’åº¦**ï¼ˆæ¯ä¸ªå­æ­¥éª¤ï¼‰ | é«˜ | é«˜ | é«˜ | é•¿æ—¶é—´è¿è¡Œã€æ˜‚è´µæ“ä½œ |

**åŠ¨æ€ç²’åº¦ç­–ç•¥**ï¼š

```python
class AdaptiveCheckpointer:
    """
    è‡ªé€‚åº”ç²’åº¦çš„ Checkpointer
    """
    def should_save(self, elapsed_time, token_cost, last_save_time):
        """
        å†³å®šæ˜¯å¦ä¿å­˜ checkpoint
        """
        # è§„åˆ™ 1: è·ç¦»ä¸Šæ¬¡ä¿å­˜è¶…è¿‡ 30 ç§’
        if time.time() - last_save_time > 30:
            return True

        # è§„åˆ™ 2: token æˆæœ¬è¶…è¿‡ $0.10
        if token_cost > 0.10:
            return True

        # è§„åˆ™ 3: æ‰§è¡Œæ—¶é—´è¶…è¿‡ 1 åˆ†é’Ÿ
        if elapsed_time > 60:
            return True

        return False
```

### 8.2 è¿‡æœŸæ¸…ç†ç­–ç•¥

**ä¿ç•™ç­–ç•¥é…ç½®**ï¼š

```python
class CheckpointRetentionPolicy:
    """
    Checkpoint ä¿ç•™ç­–ç•¥
    """
    def __init__(self, config):
        self.max_age_days = config.get('max_age_days', 7)
        self.keep_latest_n = config.get('keep_latest_n', 10)
        self.keep_completed_forever = config.get('keep_completed_forever', True)

    def should_delete(self, checkpoint):
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ é™¤ checkpoint
        """
        # å·²å®Œæˆä»»åŠ¡çš„æœ€ç»ˆçŠ¶æ€æ°¸ä¹…ä¿ç•™
        if self.keep_completed_forever and checkpoint.get('is_final'):
            return False

        # æ£€æŸ¥å¹´é¾„
        age_days = (time.time() - checkpoint['timestamp']) / 86400
        if age_days > self.max_age_days:
            return True

        return False

    def cleanup(self, checkpointer, thread_id):
        """
        æ¸…ç†è¿‡æœŸ checkpoint
        """
        checkpoints = checkpointer.get_history(thread_id)

        # ä¿ç•™æœ€æ–°çš„ N ä¸ª
        checkpoints_to_keep = sorted(
            checkpoints,
            key=lambda x: x['timestamp'],
            reverse=True
        )[:self.keep_latest_n]

        keep_ids = {c['checkpoint_id'] for c in checkpoints_to_keep}

        # åˆ é™¤å…¶ä»–è¿‡æœŸçš„
        for checkpoint in checkpoints:
            if checkpoint['checkpoint_id'] not in keep_ids:
                if self.should_delete(checkpoint):
                    checkpointer.delete(checkpoint['checkpoint_id'])

# ä½¿ç”¨ç¤ºä¾‹
policy = CheckpointRetentionPolicy({
    'max_age_days': 7,
    'keep_latest_n': 10,
    'keep_completed_forever': True
})

# å®šæœŸæ¸…ç†ï¼ˆå¯ä»¥ç”¨ cron jobï¼‰
policy.cleanup(checkpointer, "thread_001")
```

### 8.3 ç›‘æ§ä¸å¯è§‚æµ‹æ€§

**å…³é”®æŒ‡æ ‡**ï¼š

```python
from prometheus_client import Counter, Histogram, Gauge

# å®šä¹‰æŒ‡æ ‡
checkpoint_save_duration = Histogram(
    'checkpoint_save_duration_seconds',
    'Time spent saving checkpoint'
)

checkpoint_size_bytes = Histogram(
    'checkpoint_size_bytes',
    'Size of checkpoint in bytes'
)

checkpoint_restore_total = Counter(
    'checkpoint_restore_total',
    'Total number of checkpoint restores'
)

active_threads = Gauge(
    'active_threads',
    'Number of active threads'
)

# é›†æˆåˆ° Checkpointer
class ObservableCheckpointer:
    """
    å¸¦ç›‘æ§çš„ Checkpointer
    """
    def save(self, thread_id, checkpoint_data):
        start_time = time.time()

        # åºåˆ—åŒ–
        serialized = pickle.dumps(checkpoint_data)
        size = len(serialized)

        # å†™å…¥å­˜å‚¨
        self._write(thread_id, serialized)

        # è®°å½•æŒ‡æ ‡
        duration = time.time() - start_time
        checkpoint_save_duration.observe(duration)
        checkpoint_size_bytes.observe(size)

        # å‘Šè­¦ï¼šcheckpoint è¿‡å¤§
        if size > 1024 * 1024:  # > 1MB
            logging.warning(f"Large checkpoint detected: {thread_id}, size={size}")

    def restore(self, thread_id):
        checkpoint_restore_total.inc()

        start_time = time.time()
        data = self._read(thread_id)
        duration = time.time() - start_time

        logging.info(f"Checkpoint restored: {thread_id}, duration={duration:.2f}s")

        return pickle.loads(data)
```

**æ—¥å¿—è®°å½•**ï¼š

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('checkpoints.log'),
        logging.StreamHandler()
    ]
)

# åœ¨å…³é”®ç‚¹è®°å½•æ—¥å¿—
logging.info(f"Checkpoint saved: thread={thread_id}, node={node_name}, size={size}KB")
logging.warning(f"Checkpoint size exceeds threshold: {size}KB > 100KB")
logging.error(f"Failed to save checkpoint: {thread_id}, error={error}")
```

---

## 9. å®æˆ˜æ¡ˆä¾‹

### 9.1 å®Œæ•´çš„ CoT æ¨ç†ç³»ç»Ÿ

ç»“åˆä¹‹å‰çš„ CoT æ¡†æ¶ï¼Œæ·»åŠ å®Œæ•´çš„ checkpoint æ”¯æŒã€‚

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
from typing import TypedDict, List, Dict, Any
import sqlite3

# 1. çŠ¶æ€å®šä¹‰ï¼ˆä¸ CoT_studing.py ä¸€è‡´ï¼‰
class CoTState(TypedDict):
    question: str
    thoughts: List[str]
    reasoning_steps: List[Dict[str, Any]]
    final_answer: str
    current_step: int
    is_complete: bool

# 2. åˆ›å»ºå¸¦ checkpoint çš„ CoT Agent
class CheckpointedCoTAgent:
    def __init__(self, checkpoint_db="cot_checkpoints.db"):
        # åˆå§‹åŒ– checkpointer
        conn = sqlite3.connect(checkpoint_db, check_same_thread=False)
        self.checkpointer = SqliteSaver(conn)

        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(model="gpt-4", temperature=0)

        # æ„å»ºå›¾
        self.graph = self._create_graph()

    def _create_graph(self):
        workflow = StateGraph(CoTState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("analyze", self.analyze_question)
        workflow.add_node("execute", self.execute_reasoning_step)
        workflow.add_node("validate", self.validate_and_conclude)

        # è®¾ç½®æµç¨‹
        workflow.set_entry_point("analyze")
        workflow.add_conditional_edges(
            "analyze",
            lambda x: "execute" if len(x["reasoning_steps"]) > 0 else "validate"
        )
        workflow.add_conditional_edges(
            "execute",
            lambda x: "execute" if x["current_step"] < len(x["reasoning_steps"]) else "validate"
        )
        workflow.add_edge("validate", END)

        # ç¼–è¯‘æ—¶ä¼ å…¥ checkpointer
        return workflow.compile(checkpointer=self.checkpointer)

    def analyze_question(self, state: CoTState) -> CoTState:
        print("ğŸ” åˆ†æé—®é¢˜...")
        # ... å®ç°é€»è¾‘ï¼ˆä¸åŸä»£ç ç›¸åŒï¼‰
        return state

    def execute_reasoning_step(self, state: CoTState) -> CoTState:
        print(f"ğŸ”„ æ‰§è¡Œæ­¥éª¤ {state['current_step'] + 1}...")
        # ... å®ç°é€»è¾‘ï¼ˆä¸åŸä»£ç ç›¸åŒï¼‰
        return state

    def validate_and_conclude(self, state: CoTState) -> CoTState:
        print("âœ… éªŒè¯ç»“æœ...")
        # ... å®ç°é€»è¾‘ï¼ˆä¸åŸä»£ç ç›¸åŒï¼‰
        return state

    def reason(self, question: str, thread_id: str = None):
        """
        æ‰§è¡Œæ¨ç†ï¼Œæ”¯æŒæ–­ç‚¹ç»­æ¨
        """
        # ç”Ÿæˆ thread_id
        if not thread_id:
            thread_id = f"cot_{int(time.time() * 1000)}"

        config = {"configurable": {"thread_id": thread_id}}

        # æ£€æŸ¥æ˜¯å¦æœ‰å·²å­˜åœ¨çš„ checkpoint
        existing_state = None
        try:
            existing_state = self.graph.get_state(config)
        except:
            pass

        if existing_state and existing_state.values:
            print(f"ğŸ“‚ å‘ç°å·²å­˜åœ¨çš„æ¨ç†ä»»åŠ¡ï¼Œä»æ­¥éª¤ {existing_state.values['current_step']} ç»§ç»­...")
            result = self.graph.invoke(None, config=config)
        else:
            print(f"ğŸš€ å¼€å§‹æ–°çš„æ¨ç†ä»»åŠ¡...")
            initial_state = {
                "question": question,
                "thoughts": [],
                "reasoning_steps": [],
                "final_answer": "",
                "current_step": 0,
                "is_complete": False
            }
            result = self.graph.invoke(initial_state, config=config)

        return result, thread_id

# 3. ä½¿ç”¨ç¤ºä¾‹
agent = CheckpointedCoTAgent()

# ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼ˆå¯èƒ½å¤±è´¥ï¼‰
question = "å¦‚æœä¸€ä¸ªå…¬å¸æœ‰100åå‘˜å·¥ï¼Œå…¶ä¸­60%æ˜¯æŠ€æœ¯äººå‘˜ï¼Œ30%æ˜¯é”€å”®äººå‘˜..."
try:
    result, thread_id = agent.reason(question, thread_id="demo_task_001")
    print(f"\nâœ… æ¨ç†å®Œæˆ: {result['final_answer']}")
except Exception as e:
    print(f"\nâŒ æ¨ç†å¤±è´¥: {e}")
    print("å¯ä»¥ä½¿ç”¨ç›¸åŒçš„ thread_id æ¢å¤æ‰§è¡Œ")

# æ¢å¤æ‰§è¡Œ
result, thread_id = agent.reason(question, thread_id="demo_task_001")
print(f"\nâœ… æ¢å¤åå®Œæˆ: {result['final_answer']}")

# æŸ¥çœ‹å†å²
history = agent.graph.get_state_history({"configurable": {"thread_id": "demo_task_001"}})
print(f"\nğŸ“Š å…±ä¿å­˜äº† {len(list(history))} ä¸ª checkpoint")
```

### 9.2 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ç¤ºä¾‹

**å®Œæ•´çš„ç”Ÿäº§çº§é…ç½®**ï¼š

```python
import os
from dataclasses import dataclass

@dataclass
class CheckpointConfig:
    """Checkpoint é…ç½®"""
    storage_type: str = "postgresql"  # postgresql/redis/s3
    connection_string: str = os.getenv("CHECKPOINT_DB_URL")
    max_checkpoints_per_thread: int = 10
    checkpoint_ttl_days: int = 7
    enable_compression: bool = True
    enable_encryption: bool = True

class ProductionCoTAgent(CheckpointedCoTAgent):
    """
    ç”Ÿäº§çº§ CoT Agent
    """
    def __init__(self, config: CheckpointConfig):
        self.config = config
        self.checkpointer = self._create_checkpointer()
        self.llm = self._create_llm()
        self.cost_tracker = CostTracker()
        self.failover_manager = FailoverManager(self.checkpointer)

        self.graph = self._create_graph()

    def _create_checkpointer(self):
        """æ ¹æ®é…ç½®åˆ›å»º checkpointer"""
        if self.config.storage_type == "postgresql":
            from langgraph.checkpoint.postgres import PostgresSaver
            import psycopg2

            conn = psycopg2.connect(self.config.connection_string)
            checkpointer = PostgresSaver(conn)
            checkpointer.setup()
            return checkpointer

        elif self.config.storage_type == "redis":
            return RedisCheckpointer(self.config.connection_string)

        else:
            raise ValueError(f"Unsupported storage type: {self.config.storage_type}")

    def reason_with_monitoring(self, question: str, thread_id: str, budget: float = 1.0):
        """
        å¸¦ç›‘æ§å’Œæˆæœ¬æ§åˆ¶çš„æ¨ç†
        """
        config = {"configurable": {"thread_id": thread_id}}

        # æ£€æŸ¥ç°æœ‰æˆæœ¬
        existing_state = self.graph.get_state(config)
        if existing_state and existing_state.values:
            existing_cost = existing_state.values.get('total_cost', 0)
            if existing_cost >= budget:
                raise BudgetExceededError(f"å·²è¶…å‡ºé¢„ç®—: ${existing_cost:.2f} >= ${budget:.2f}")

        # æ³¨å†Œåˆ°æ•…éšœè½¬ç§»ç®¡ç†å™¨
        self.failover_manager.register_task(thread_id)

        try:
            # æ‰§è¡Œæ¨ç†
            result, _ = self.reason(question, thread_id)

            # è®°å½•æˆæœ¬
            final_cost = self.cost_tracker.get_cost()
            logging.info(f"ä»»åŠ¡å®Œæˆ: thread={thread_id}, cost=${final_cost:.4f}")

            return result

        finally:
            # æ¸…ç†
            if thread_id in self.failover_manager.active_tasks:
                del self.failover_manager.active_tasks[thread_id]

# éƒ¨ç½²
config = CheckpointConfig(
    storage_type="postgresql",
    connection_string="postgresql://user:pass@db.example.com:5432/llm_app",
    max_checkpoints_per_thread=10,
    checkpoint_ttl_days=7
)

agent = ProductionCoTAgent(config)

# æ‰§è¡Œä»»åŠ¡
result = agent.reason_with_monitoring(
    question="å¤æ‚é—®é¢˜...",
    thread_id="prod_task_12345",
    budget=5.0  # æœ€å¤šèŠ±è´¹ $5
)
```

---

## 10. æ€§èƒ½ä¼˜åŒ–ä¸å¸¸è§é—®é¢˜

### 10.1 æ€§èƒ½ä¼˜åŒ–æŠ€å·§

**1. å¢é‡åºåˆ—åŒ–**

åªä¿å­˜çŠ¶æ€å·®å¼‚è€Œéå®Œæ•´çŠ¶æ€ï¼š

```python
def compute_delta(old_state, new_state):
    """è®¡ç®—çŠ¶æ€å·®å¼‚"""
    delta = {}
    for key, new_value in new_state.items():
        old_value = old_state.get(key)
        if old_value != new_value:
            delta[key] = new_value
    return delta

def apply_delta(base_state, delta):
    """åº”ç”¨çŠ¶æ€å·®å¼‚"""
    return {**base_state, **delta}

# ä½¿ç”¨ç¤ºä¾‹
old_checkpoint = checkpointer.get_latest("thread_001")
delta = compute_delta(old_checkpoint['state'], new_state)

# åªä¿å­˜å·®å¼‚ï¼ˆèŠ‚çœå­˜å‚¨ç©ºé—´ï¼‰
checkpointer.save_delta("thread_001", delta, parent_id=old_checkpoint['id'])
```

**2. å‹ç¼©**

```python
import gzip
import pickle

def compress_checkpoint(checkpoint_data):
    """å‹ç¼© checkpoint"""
    serialized = pickle.dumps(checkpoint_data)
    compressed = gzip.compress(serialized, compresslevel=6)
    return compressed

def decompress_checkpoint(compressed_data):
    """è§£å‹ checkpoint"""
    decompressed = gzip.decompress(compressed_data)
    return pickle.loads(decompressed)

# å¯¹äºå¤§å‹çŠ¶æ€ï¼Œå¯ä»¥èŠ‚çœ 50-80% çš„å­˜å‚¨ç©ºé—´
```

**3. å¼‚æ­¥ä¿å­˜**

```python
from concurrent.futures import ThreadPoolExecutor
import queue

class AsyncCheckpointer:
    """å¼‚æ­¥ Checkpointer"""
    def __init__(self, base_checkpointer, max_workers=4):
        self.base = base_checkpointer
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.save_queue = queue.Queue()

    def save_async(self, thread_id, checkpoint_data):
        """
        å¼‚æ­¥ä¿å­˜ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        """
        future = self.executor.submit(
            self.base.save,
            thread_id,
            checkpoint_data
        )
        return future

    def save_sync(self, thread_id, checkpoint_data):
        """
        åŒæ­¥ä¿å­˜ï¼ˆç¡®ä¿æŒä¹…åŒ–ï¼‰
        """
        return self.base.save(thread_id, checkpoint_data)
```

### 10.2 å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

**é—®é¢˜ 1ï¼šCheckpoint ä½“ç§¯è¿‡å¤§**

```
ç—‡çŠ¶ï¼šå•ä¸ª checkpoint è¶…è¿‡ 1MBï¼Œå¯¼è‡´ä¿å­˜/åŠ è½½ç¼“æ…¢
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç§»é™¤ä¸å¿…è¦çš„ä¸­é—´æ•°æ®
- åªä¿å­˜æœ€ç»ˆç»“æœï¼Œä¸ä¿å­˜å…¨éƒ¨ LLM å“åº”
- ä½¿ç”¨å‹ç¼©
- å°†å¤§æ•°æ®ï¼ˆå¦‚æ–‡ä»¶ï¼‰å­˜å‚¨åˆ°å¯¹è±¡å­˜å‚¨ï¼Œcheckpoint ä¸­åªä¿å­˜å¼•ç”¨

```python
# ä¸å¥½çš„åšæ³•
state = {
    "full_llm_responses": [...],  # åŒ…å«æ‰€æœ‰åŸå§‹å“åº”
    "intermediate_data": [...],   # å¤§é‡ä¸­é—´æ•°æ®
}

# å¥½çš„åšæ³•
state = {
    "summary": "...",            # åªä¿å­˜æ‘˜è¦
    "final_result": "...",       # åªä¿å­˜æœ€ç»ˆç»“æœ
    "llm_response_ids": [...]    # å¼•ç”¨ï¼ŒçœŸå®æ•°æ®å­˜åœ¨ S3
}
```

**é—®é¢˜ 2ï¼šå¹¶å‘å†™å…¥å†²çª**

```
ç—‡çŠ¶ï¼šå¤šä¸ªè¿›ç¨‹åŒæ—¶ä¿®æ”¹åŒä¸€ä¸ª threadï¼Œå¯¼è‡´çŠ¶æ€ä¸ä¸€è‡´
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ä¹è§‚é”ï¼ˆç‰ˆæœ¬å·ï¼‰
- æ¯ä¸ªè¿›ç¨‹ä½¿ç”¨å”¯ä¸€çš„ thread_id
- ä½¿ç”¨åˆ†å¸ƒå¼é”ï¼ˆRedis SETNXï¼‰

**é—®é¢˜ 3ï¼šæ¢å¤åè¡Œä¸ºä¸ä¸€è‡´**

```
ç—‡çŠ¶ï¼šä» checkpoint æ¢å¤åï¼Œæ‰§è¡Œç»“æœä¸åŸå§‹æ‰§è¡Œä¸åŒ
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®ä¿èŠ‚ç‚¹å¹‚ç­‰æ€§
- ç¼“å­˜ LLM å“åº”
- ä½¿ç”¨ temperature=0
- è®°å½•éšæœºç§å­

**é—®é¢˜ 4ï¼šå†…å­˜æ³„æ¼**

```
ç—‡çŠ¶ï¼šé•¿æ—¶é—´è¿è¡Œåå†…å­˜å ç”¨æŒç»­å¢é•¿
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å®šæœŸæ¸…ç†è¿‡æœŸ checkpoint
- é™åˆ¶ checkpoint æ•°é‡
- ä½¿ç”¨å¼±å¼•ç”¨
- åŠæ—¶å…³é—­æ•°æ®åº“è¿æ¥

```python
# å®šæœŸæ¸…ç†
import schedule

def cleanup_old_checkpoints():
    policy = CheckpointRetentionPolicy({'max_age_days': 7})
    # ... æ¸…ç†é€»è¾‘

schedule.every().day.at("02:00").do(cleanup_old_checkpoints)
```

---

## æ€»ç»“

æ–­ç‚¹ç»­æ¨å’Œå›æº¯æŠ€æœ¯æ˜¯æ„å»ºå¯é  LLM åº”ç”¨çš„åŸºç¡€è®¾æ–½ï¼Œå®ƒä»¬è§£å†³äº†ä»¥ä¸‹æ ¸å¿ƒé—®é¢˜ï¼š

1. **å¯é æ€§**ï¼šé€šè¿‡ checkpoint æœºåˆ¶ï¼Œç¡®ä¿ä»»åŠ¡å¯ä»¥ä»å¤±è´¥ç‚¹æ¢å¤
2. **å¯è¿½æº¯æ€§**ï¼šå®Œæ•´è®°å½•æ‰§è¡Œå†å²ï¼Œæ”¯æŒå®¡è®¡å’Œè°ƒè¯•
3. **çµæ´»æ€§**ï¼šæ”¯æŒæ—¶é—´æ—…è¡Œå’Œåˆ†æ”¯ç®¡ç†ï¼Œå®ç°å¤æ‚çš„æ¨ç†æµç¨‹
4. **å¯æ‰©å±•æ€§**ï¼šé€šè¿‡åˆ†å¸ƒå¼å­˜å‚¨å’Œæ•…éšœè½¬ç§»ï¼Œæ”¯æŒå¤§è§„æ¨¡éƒ¨ç½²

**å…³é”®è¦ç‚¹**ï¼š

- **é€‰æ‹©åˆé€‚çš„å­˜å‚¨åç«¯**ï¼šå¼€å‘ç”¨ SQLiteï¼Œç”Ÿäº§ç”¨ PostgreSQL/Redis
- **å¹³è¡¡ checkpoint ç²’åº¦**ï¼šè¿‡ç»†å¢åŠ å¼€é”€ï¼Œè¿‡ç²—é™ä½æ¢å¤ç²¾åº¦
- **ç¡®ä¿èŠ‚ç‚¹å¹‚ç­‰æ€§**ï¼šæ¢å¤æ‰§è¡Œæ—¶çš„ä¸€è‡´æ€§åŸºç¡€
- **ç›‘æ§å’Œå‘Šè­¦**ï¼šåŠæ—¶å‘ç°å’Œå¤„ç†å¼‚å¸¸
- **æˆæœ¬æ§åˆ¶**ï¼šè®°å½• token ä½¿ç”¨ï¼Œé¿å…é¢„ç®—è¶…æ”¯

é€šè¿‡åˆç†åº”ç”¨è¿™äº›æŠ€æœ¯ï¼Œä½ çš„ LLM åº”ç”¨å°†å…·å¤‡ç”Ÿäº§çº§çš„å¯é æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

---

## å‚è€ƒèµ„æº

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [LangGraph Checkpointing Guide](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Redis Documentation](https://redis.io/docs/)
- [Design Patterns for Distributed Systems](https://martinfowler.com/articles/patterns-of-distributed-systems/)

**ç‰ˆæœ¬**ï¼šv1.0
**æ—¥æœŸ**ï¼š2025-01-XX
**License**ï¼šCC BY-NC-SA 4.0
